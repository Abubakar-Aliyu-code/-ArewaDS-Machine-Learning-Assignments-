{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy (train) for Linear SVC: 76.4% \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "     chinese       0.65      0.69      0.67       235\n",
      "      indian       0.82      0.89      0.86       236\n",
      "    japanese       0.75      0.69      0.72       253\n",
      "      korean       0.86      0.74      0.80       238\n",
      "        thai       0.75      0.82      0.78       237\n",
      "\n",
      "    accuracy                           0.76      1199\n",
      "   macro avg       0.77      0.76      0.76      1199\n",
      "weighted avg       0.77      0.76      0.76      1199\n",
      "\n",
      "Accuracy (train) for KNN classifier: 71.1% \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "     chinese       0.76      0.60      0.67       235\n",
      "      indian       0.84      0.81      0.82       236\n",
      "    japanese       0.57      0.83      0.68       253\n",
      "      korean       0.94      0.55      0.69       238\n",
      "        thai       0.65      0.76      0.70       237\n",
      "\n",
      "    accuracy                           0.71      1199\n",
      "   macro avg       0.75      0.71      0.71      1199\n",
      "weighted avg       0.75      0.71      0.71      1199\n",
      "\n",
      "Accuracy (train) for SVC: 80.2% \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "     chinese       0.74      0.71      0.73       235\n",
      "      indian       0.90      0.88      0.89       236\n",
      "    japanese       0.76      0.77      0.76       253\n",
      "      korean       0.90      0.79      0.84       238\n",
      "        thai       0.74      0.85      0.79       237\n",
      "\n",
      "    accuracy                           0.80      1199\n",
      "   macro avg       0.81      0.80      0.80      1199\n",
      "weighted avg       0.81      0.80      0.80      1199\n",
      "\n",
      "Accuracy (train) for RFST: 83.0% \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "     chinese       0.81      0.75      0.78       235\n",
      "      indian       0.89      0.92      0.90       236\n",
      "    japanese       0.83      0.78      0.80       253\n",
      "      korean       0.87      0.82      0.84       238\n",
      "        thai       0.77      0.87      0.82       237\n",
      "\n",
      "    accuracy                           0.83      1199\n",
      "   macro avg       0.83      0.83      0.83      1199\n",
      "weighted avg       0.83      0.83      0.83      1199\n",
      "\n",
      "Accuracy (train) for ADA: 68.8% \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "     chinese       0.56      0.40      0.47       235\n",
      "      indian       0.81      0.86      0.83       236\n",
      "    japanese       0.63      0.68      0.65       253\n",
      "      korean       0.72      0.72      0.72       238\n",
      "        thai       0.69      0.78      0.73       237\n",
      "\n",
      "    accuracy                           0.69      1199\n",
      "   macro avg       0.68      0.69      0.68      1199\n",
      "weighted avg       0.68      0.69      0.68      1199\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.ensemble import RandomForestClassifier, AdaBoostClassifier\n",
    "from sklearn.model_selection import train_test_split, cross_val_score\n",
    "from sklearn.metrics import accuracy_score,precision_score,confusion_matrix,classification_report, precision_recall_curve\n",
    "import numpy as np\n",
    "\n",
    "#In this second classification lesson, you will explore more ways to classify numeric data. \n",
    "# You will also learn about the ramifications for choosing one classifier over the other.\n",
    "\n",
    "cleaned_cuisine = pd.read_csv(\"C:\\\\Users\\HP\\Desktop\\\\-ArewaDS-Machine-Learning-Assignments-\\\\Data\\\\cleaned_cuisines.csv\")\n",
    "cleaned_cuisine.head()\n",
    "\n",
    "#Divide the X and y coordinates into two dataframes for training. cuisine can be the labels dataframe:\n",
    "\n",
    "cuisines_label_df = cleaned_cuisine['cuisine']\n",
    "cuisines_label_df.head()\n",
    "\n",
    "#Drop that Unnamed: 0 column and the cuisine column, calling drop(). Save the rest of the data as trainable features:\n",
    "\n",
    "cuisines_feature_df = cleaned_cuisine.drop(['Unnamed: 0', 'cuisine'], axis=1)\n",
    "cuisines_feature_df.head()\n",
    "\n",
    "#Split your training and test data:\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(cuisines_feature_df, cuisines_label_df, test_size=0.3)\n",
    "\n",
    "#APPLY Linear SVC classifier...\n",
    "# Support-Vector clustering (SVC) is a child of the Support-Vector machines family of ML techniques.\n",
    "#In this method, you can choose a 'kernel' to decide how to cluster the labels. \n",
    "# The 'C' parameter refers to 'regularization' which regulates the influence of parameters. \n",
    "# The kernel can be one of several; here we set it to 'linear' to ensure that we leverage linear SVC. \n",
    "# Probability defaults to 'false'; here we set it to 'true' to gather probability estimates. \n",
    "# We set the random state to '0' to shuffle the data to get probabilities.\n",
    "\n",
    "C = 10\n",
    "# Create different classifiers.\n",
    "classifiers = {\n",
    "    'Linear SVC': SVC(kernel='linear', C=C, probability=True,random_state=0), 'KNN classifier': KNeighborsClassifier(C), 'SVC': SVC(),   \n",
    "    'RFST': RandomForestClassifier(n_estimators=100),  'ADA': AdaBoostClassifier(n_estimators=100)\n",
    "}\n",
    "\n",
    "#Train your model using the Linear SVC and print out a report:\n",
    "\n",
    "n_classifiers = len(classifiers)\n",
    "\n",
    "for index, (name, classifier) in enumerate(classifiers.items()):\n",
    "    classifier.fit(X_train, np.ravel(y_train))\n",
    "\n",
    "    y_pred = classifier.predict(X_test)\n",
    "    accuracy = accuracy_score(y_test, y_pred)\n",
    "    print(\"Accuracy (train) for %s: %0.1f%% \" % (name, accuracy * 100))\n",
    "    print(classification_report(y_test,y_pred))\n",
    "\n",
    "#APPLY K-Neighbors classifier\n",
    "#K-Neighbors is part of the \"neighbors\" family of ML methods, \n",
    "# which can be used for both supervised and unsupervised learning. \n",
    "# In this method, a predefined number of points is created and data are gathered around these points\n",
    "# such that generalized labels can be predicted for the data.\n",
    "# Add a line to your classifier array (add a comma after the Linear SVC item): 'KNN classifier': KNeighborsClassifier(C),\n",
    "\n",
    "#APPLY Support Vector Classifier\n",
    "#Support-Vector classifiers are part of the Support-Vector Machine family of ML methods that are used for classification \n",
    "# and regression tasks. SVMs \"map training examples to points in space\" to maximize the distance between two categories. \n",
    "# Subsequent data is mapped into this space so their category can be predicted. \n",
    "# Add a comma after the K-Neighbors item, and then add this line:'SVC': SVC(),\n",
    "\n",
    "#APPLY Ensemble Classifiers\n",
    "#Let's follow the path to the very end, even though the previous test was quite good. Let's try some 'Ensemble Classifiers, \n",
    "# specifically Random Forest and AdaBoost:   'RFST': RandomForestClassifier(n_estimators=100), 'ADA': AdaBoostClassifier(n_estimators=100)\n",
    "\n",
    "\n",
    "#CONCLUSION\n",
    "#There are a lot of parameters that are set by default when working with these classifiers.\n",
    "# Intellisense in VS Code can help you dig into them. Adopt one of the ML Classification Techniques in this lesson and retrain models \n",
    "# tweaking various parameter values. Build a notebook explaining why some changes help the model quality while others degrade it. \n",
    "# Be detailed in your answer.\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
