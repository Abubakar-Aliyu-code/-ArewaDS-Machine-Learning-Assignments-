{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 3995 entries, 0 to 3994\n",
      "Columns: 381 entries, cuisine to zucchini\n",
      "dtypes: int64(380), object(1)\n",
      "memory usage: 11.6+ MB\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib as mpl\n",
    "import numpy as np\n",
    "from imblearn.over_sampling import SMOTE\n",
    "\n",
    "#IMPORTING AND READING THE DATA\n",
    "cuisine = pd.read_csv('C:\\\\Users\\HP\\Desktop\\\\-ArewaDS-Machine-Learning-Assignments-\\\\Data\\\\cuisines.csv') \n",
    "#cuisine.tail()\n",
    "#GET More INFORMATION ABOUT THE DATA\n",
    "#cuisine.info()\n",
    "\n",
    "# Discover the distribution of data, per cuisine\n",
    "#cuisine.cuisine.value_counts().plot.barh()\n",
    "\n",
    "#Find out how much data is available per cuisine and print it out:\n",
    "\n",
    "thai_cuisine = cuisine[(cuisine.cuisine == \"thai\")]\n",
    "japanese_cuisine = cuisine[(cuisine.cuisine == \"japanese\")]\n",
    "chinese_cuisine = cuisine[(cuisine.cuisine == \"chinese\")]\n",
    "indian_cuisine = cuisine[(cuisine.cuisine == \"indian\")]\n",
    "korean_cuisine = cuisine[(cuisine.cuisine == \"korean\")]\n",
    "\n",
    "#print(f'thai cuisine: {thai_cuisine.shape}')\n",
    "#print(f'japanese cuisine: {japanese_cuisine.shape}')\n",
    "#print(f'chinese cuisine: {chinese_cuisine.shape}')\n",
    "#print(f'indian cuisine: {indian_cuisine.shape}')\n",
    "#print(f'korean cuisine: {korean_cuisine.shape}')\n",
    "\n",
    "\n",
    "#Now you can dig deeper into the data and learn what are the typical ingredients per cuisine. \n",
    "# You should clean out recurrent data that creates confusion between cuisines, so let's learn about this problem.\n",
    "\n",
    "#Create a function create_ingredient() in Python to create an ingredient dataframe. \n",
    "# This function will start by dropping an unhelpful column and sort through ingredients by their count:\n",
    "\n",
    "def create_ingredient_df(df):\n",
    "    ingredient_df = df.T.drop(['cuisine','Unnamed: 0']).sum(axis=1).to_frame('value')\n",
    "    ingredient_df = ingredient_df[(ingredient_df.T != 0).any()]\n",
    "    ingredient_df = ingredient_df.sort_values(by='value', ascending=False,\n",
    "    inplace=False)\n",
    "    return ingredient_df\n",
    "\n",
    "\n",
    "#Use that function to get an idea of top ten most popular ingredients by cuisine.\n",
    "\n",
    "\n",
    "thai_ingredient_df = create_ingredient_df(thai_cuisine)\n",
    "#thai_ingredient_df.head(10).plot.barh()\n",
    "\n",
    "#DO THE SAME FOR THE OTHER INGREDIENTS\n",
    "\n",
    "japanese_ingredient_df = create_ingredient_df(japanese_cuisine)\n",
    "#japanese_ingredient_df.head(10).plot.barh()\n",
    "\n",
    "chinese_ingredient_df = create_ingredient_df(chinese_cuisine)\n",
    "#chinese_ingredient_df.head(10).plot.barh()\n",
    "\n",
    "indian_ingredient_df = create_ingredient_df(indian_cuisine)\n",
    "#indian_ingredient_df.head(10).plot.barh()\n",
    "\n",
    "korean_ingredient_df = create_ingredient_df(korean_cuisine)\n",
    "#korean_ingredient_df.head(10).plot.barh()\n",
    "\n",
    "#Now, drop the most common ingredients that create confusion between distinct cuisines, by calling drop():\n",
    "#Everyone loves rice, garlic and ginger!\n",
    "\n",
    "feature_df= cuisine.drop(['cuisine','Unnamed: 0','rice','garlic','ginger'], axis=1)\n",
    "labels_df = cuisine.cuisine #.unique()\n",
    "feature_df.head()\n",
    "\n",
    "#Now that you have cleaned the data, use SMOTE - \"Synthetic Minority Over-sampling Technique\" - to balance it.\n",
    "#Call fit_resample(), this strategy generates new samples by interpolation. By balancing your data, you'll have better results\n",
    "# when classifying it. Think about a binary classification. If most of your data is one class, a ML model is going to predict \n",
    "# that class more frequently, just because there is more data for it. Balancing the data takes any skewed data and helps remove this imbalance.\n",
    "\n",
    "oversample = SMOTE()\n",
    "transformed_feature_df, transformed_label_df = oversample.fit_resample(feature_df, labels_df)\n",
    "\n",
    "#Now you can check the numbers of labels per ingredient:\n",
    "\n",
    "#print(f'new label count: {transformed_label_df.value_counts()}')\n",
    "#print(f'old label count: {cuisine.cuisine.value_counts()}')\n",
    "\n",
    "#The last step is to save your balanced data, including labels and features, into a new dataframe that can be exported into a file:\n",
    "\n",
    "transformed_df = pd.concat([transformed_label_df,transformed_feature_df],axis=1, join='outer')\n",
    "\n",
    "#You can take one more look at the data using transformed_df.head() and transformed_df.info(). \n",
    "# Save a copy of this data for use in future lessons:\n",
    "\n",
    "transformed_df.head()\n",
    "transformed_df.info()\n",
    "transformed_df.to_csv(\"C:\\\\Users\\HP\\Desktop\\\\-ArewaDS-Machine-Learning-Assignments-\\\\Data\\\\cleaned_cuisines.csv\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.4"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
